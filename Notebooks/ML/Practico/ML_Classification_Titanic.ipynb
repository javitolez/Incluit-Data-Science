{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCLUIT - Ejercicio de Machine Learning\n",
    "\n",
    "### Junio 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "\n",
    "El objetivo de este notebook es ejercitar el ajuste de un modelo de Machine Learning sobre un conjunto de datos referido a pasajeros del Titanic. En particular, el ejercicio se va a orientar a predecir la condición de supervicencia de un pasajero del Titanic a partir de las características que presentaron. Se pretende en este ejercicio entender un end-to-end del modelado para un clasificador, desde la carga de datos hasta el ajuste del modelo y validación de su desempeño.\n",
    "\n",
    "**Link a dataset:** https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "\n",
    "**Ejemplos asociados:** Dado que es un dataset popular, se puede encontrar una gran variedad de kernels disponibles para sacar ideas y corroborar otras: https://www.kaggle.com/c/titanic/kernels\n",
    "\n",
    "Como guía, se pretende que el pipeline a desarrollar cubra los siguientes aspectos (no necesariamente en este estricto orden):\n",
    "\n",
    "- **Definir enfoque analítico:** Enunciar de forma clara la tarea de clasificación que se va a desarrollar, desde la descripción de los datos de entrada, hasta la salida a obtener a partir de un modelo ajustado con un algoritmo que se eligió apropiadamente para esta tarea.\n",
    "\n",
    "- **Carga de datos:** Lectura de CSV \"train.csv\" en un DataFrame (dado que es un conjunto único de datos).\n",
    "\n",
    "- **Pre-procesamiento:** Se puede utilizar las features que se obtuvieron en [este notebook](https://www.kaggle.com/sinakhorami/titanic-best-working-classifier), aunque se deja la libertad de utilizar / extraer las features que se quieran para esta primer instancia.\n",
    "\n",
    "- **Split:** Partir DF en train-valid usando la regla 70/30.\n",
    "    \n",
    "- **Configurar modelo a ajustar:** Utilizar los algoritmos vistos en clase, donde se sugiere las siguientes implementaciones de scikit-learn:\n",
    "    - `sklearn.neighbors.KNeighborsClassifier`\n",
    "    - `sklearn.tree.DecisionTreeClassifier`\n",
    "    \n",
    "    También se recomienda utilizar algoritmos similares, cuyos fundamentos teóricos aún no fueron dados pero parten de los conceptos ya vistos en clase:\n",
    "\n",
    "    - `sklearn.ensemble.RandomForestClassifier`\n",
    "    - `sklearn.linear_model.LogisticRegression`\n",
    "    \n",
    "    Además, probar la conveniencia de hacer ajustes de hiperparámetros o bien dejar todo \"por defecto\" desde scikit-learn.\n",
    "\n",
    "- **Ajustar modelo:** Utilizar conjunto de train para ajustar el modelo definido.\n",
    "\n",
    "- **Validar modelo:** Utilizar conjunto de valid para validar el desempeño del modelo ajustado usando métricas adecuadas para problemas de regresión.\n",
    "    - En este caso se sugiere utilizar precision, recall y f1-score mediante la [API de scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics).\n",
    "\n",
    "- **Re-ajustar modelo:** En caso de que el desempeño actual no sea apropiado, volver a ajustar el modelo cambiando la configuración utilizada.\n",
    "    - En caso de que estos cambios no sean suficientes, evaluar la posibilidad de cambiar alguna etapa del pre-procesamiento de datos (garbage in, garbage out).\n",
    "\n",
    "- **Chequeo final y guardar en disco:** Se sugiere hacer una validación final sobre el conjunto \"test.csv\". Se chequea el resultado final del modelo respecto a los criterios de aceptación manejados, y se guarda en disco tanto el modelo como la salida obtenida sobre el conjunto de test.\n",
    "    \n",
    " **OPCIONAL**: Crear un dataset de 10 pasajeros \"inventados\" (datos sintéticos) para hacer pruebas del modelo obtenido.\n",
    "     - Obtener un DF de 10 filas cuyos atributos (los necesarios para las features del modelo al menos) sean inventados\n",
    "     - Entender la probabilidad de supervivencia que arroja el modelo para validar si la salida tiene sentido a partir de la entrada."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "a64839b2f6a1456582823eaa2e227ba4",
   "lastKernelId": "21a0c607-1c10-401d-a60b-f96d2695a267"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
